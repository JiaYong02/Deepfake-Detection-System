{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"464a2efc45fb461896d1ef833e96bb0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1ca2e20d7c194a8f899343a46c6a4280","IPY_MODEL_647220925d1b4fd7baafcca901db82fd","IPY_MODEL_413ed8b4590e410abc7349ae15281692"],"layout":"IPY_MODEL_015c4b25451f4848a821b2784617d9c8"}},"1ca2e20d7c194a8f899343a46c6a4280":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce6edc35d3dc448a9b3b0211c0ce5c9e","placeholder":"​","style":"IPY_MODEL_122df8e273d343be99ced55ae44035f5","value":"model.bin: 100%"}},"647220925d1b4fd7baafcca901db82fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_48f21c837361409c9fff355f0eb83391","max":3086912962,"min":0,"orientation":"horizontal","style":"IPY_MODEL_49b5f1df784c407bb905bf0bfbfd5a24","value":3086912962}},"413ed8b4590e410abc7349ae15281692":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_676d2cf4f9cf478ea7f873bb8663df75","placeholder":"​","style":"IPY_MODEL_46494db417db49ddb88b7251bd2b64e3","value":" 3.09G/3.09G [00:38&lt;00:00, 155MB/s]"}},"015c4b25451f4848a821b2784617d9c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce6edc35d3dc448a9b3b0211c0ce5c9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"122df8e273d343be99ced55ae44035f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48f21c837361409c9fff355f0eb83391":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49b5f1df784c407bb905bf0bfbfd5a24":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"676d2cf4f9cf478ea7f873bb8663df75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46494db417db49ddb88b7251bd2b64e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b71f3e001464524a1698592dddbc1bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7ea5fefa721401a982aab94044ecf2e","IPY_MODEL_64b01f3e6cce4d6ea2d09d4adacee509","IPY_MODEL_a99472e689744d32a515458eb8d4e58e"],"layout":"IPY_MODEL_c21c0030c0034243bcde470dbda95868"}},"d7ea5fefa721401a982aab94044ecf2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_764cfaa5a8864d3db69a88a090eb0431","placeholder":"​","style":"IPY_MODEL_b11e73cb1fe847c9bf005baedb70b07c","value":"tokenizer.json: 100%"}},"64b01f3e6cce4d6ea2d09d4adacee509":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e5fe3566f5844efbd54936aad692c59","max":2203239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f947b31f89b41d582fd2f19b12fd248","value":2203239}},"a99472e689744d32a515458eb8d4e58e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6bc5c35e11d4bafadc78012c52e94fd","placeholder":"​","style":"IPY_MODEL_90d3eb4e00f74cadac1e679b5a0a161a","value":" 2.20M/2.20M [00:01&lt;00:00, 2.20MB/s]"}},"c21c0030c0034243bcde470dbda95868":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"764cfaa5a8864d3db69a88a090eb0431":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b11e73cb1fe847c9bf005baedb70b07c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e5fe3566f5844efbd54936aad692c59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f947b31f89b41d582fd2f19b12fd248":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d6bc5c35e11d4bafadc78012c52e94fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90d3eb4e00f74cadac1e679b5a0a161a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58cd70590ac24792b8d08cc72bf3bafb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_efdf5530d0ee432ea9348f4d170b9670","IPY_MODEL_5b729766bee34662920ed4a7734c5133","IPY_MODEL_09d7f61e93d94d7f83b60ba96ac68d7c"],"layout":"IPY_MODEL_d777539d2d1e4423b003a88bf434d6bc"}},"efdf5530d0ee432ea9348f4d170b9670":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_176715771bbb486f95482297e105186e","placeholder":"​","style":"IPY_MODEL_edc0a80d72894607944e8ae2a3997406","value":"config.json: 100%"}},"5b729766bee34662920ed4a7734c5133":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_26783545b00d4515aa5919061f63684f","max":2796,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f2fbc2c05cad4bda8afcdd317e8bf92a","value":2796}},"09d7f61e93d94d7f83b60ba96ac68d7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7a39808aaeb4a6c88c782f17b4692fa","placeholder":"​","style":"IPY_MODEL_383e0e842f6040fa98073c995c5db35d","value":" 2.80k/2.80k [00:00&lt;00:00, 48.2kB/s]"}},"d777539d2d1e4423b003a88bf434d6bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"176715771bbb486f95482297e105186e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edc0a80d72894607944e8ae2a3997406":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26783545b00d4515aa5919061f63684f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2fbc2c05cad4bda8afcdd317e8bf92a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7a39808aaeb4a6c88c782f17b4692fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"383e0e842f6040fa98073c995c5db35d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ac69ba66b7140a2a549f75b554c51dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f87557f81f644be18837d5841183a11b","IPY_MODEL_f0eaac040b544ddf893de561a2df10ac","IPY_MODEL_b0528c5b041d41d39b9639a5677b578f"],"layout":"IPY_MODEL_ee8cb3aecce943b889f56bd57e779265"}},"f87557f81f644be18837d5841183a11b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13ad4601cecf4703ab9384033053d1ca","placeholder":"​","style":"IPY_MODEL_edd404d4a3254e03ba8073533978233b","value":"vocabulary.txt: 100%"}},"f0eaac040b544ddf893de561a2df10ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f4d3e2f56ed41d8a2780c816ffbd467","max":459861,"min":0,"orientation":"horizontal","style":"IPY_MODEL_26e75d7625034aacae5e8e7343efe8fc","value":459861}},"b0528c5b041d41d39b9639a5677b578f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c5cf27946ca4f81be0f9089a030e4bb","placeholder":"​","style":"IPY_MODEL_094e347db7064acd972dad45bdac2a4a","value":" 460k/460k [00:00&lt;00:00, 773kB/s]"}},"ee8cb3aecce943b889f56bd57e779265":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13ad4601cecf4703ab9384033053d1ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edd404d4a3254e03ba8073533978233b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f4d3e2f56ed41d8a2780c816ffbd467":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26e75d7625034aacae5e8e7343efe8fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c5cf27946ca4f81be0f9089a030e4bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"094e347db7064acd972dad45bdac2a4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8780766,"sourceType":"datasetVersion","datasetId":5278038},{"sourceId":8791772,"sourceType":"datasetVersion","datasetId":5285955}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install Packages","metadata":{"id":"6bfZcMvucu7H"}},{"cell_type":"code","source":"# Install WhisperX\n! pip install git+https://github.com/m-bain/whisperx.git\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hjdbcV4VctSz","outputId":"9360d5a0-4896-462c-b52d-ee91b027a525","execution":{"iopub.status.busy":"2024-06-26T11:27:21.774652Z","iopub.execute_input":"2024-06-26T11:27:21.775533Z","iopub.status.idle":"2024-06-26T11:28:28.013654Z","shell.execute_reply.started":"2024-06-26T11:27:21.775484Z","shell.execute_reply":"2024-06-26T11:28:28.012461Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/m-bain/whisperx.git\n  Cloning https://github.com/m-bain/whisperx.git to /tmp/pip-req-build-9g1lcqxe\n  Running command git clone --filter=blob:none --quiet https://github.com/m-bain/whisperx.git /tmp/pip-req-build-9g1lcqxe\n  Resolved https://github.com/m-bain/whisperx.git to commit f2da2f858e99e4211fe4f64b5f2938b007827e17\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch>=2 in /opt/conda/lib/python3.10/site-packages (from whisperx==3.1.1) (2.1.2)\nRequirement already satisfied: torchaudio>=2 in /opt/conda/lib/python3.10/site-packages (from whisperx==3.1.1) (2.1.2)\nCollecting faster-whisper==1.0.0 (from whisperx==3.1.1)\n  Downloading faster_whisper-1.0.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from whisperx==3.1.1) (4.41.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from whisperx==3.1.1) (2.2.1)\nRequirement already satisfied: setuptools>=65 in /opt/conda/lib/python3.10/site-packages (from whisperx==3.1.1) (69.0.3)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from whisperx==3.1.1) (3.2.4)\nCollecting pyannote.audio==3.1.1 (from whisperx==3.1.1)\n  Downloading pyannote.audio-3.1.1-py2.py3-none-any.whl.metadata (9.3 kB)\nCollecting av==11.* (from faster-whisper==1.0.0->whisperx==3.1.1)\n  Downloading av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\nCollecting ctranslate2<5,>=4.0 (from faster-whisper==1.0.0->whisperx==3.1.1)\n  Downloading ctranslate2-4.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: huggingface-hub>=0.13 in /opt/conda/lib/python3.10/site-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (0.23.2)\nCollecting tokenizers<0.16,>=0.13 (from faster-whisper==1.0.0->whisperx==3.1.1)\n  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nCollecting onnxruntime<2,>=1.14 (from faster-whisper==1.0.0->whisperx==3.1.1)\n  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\nCollecting asteroid-filterbanks>=0.4 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting einops>=0.6.0 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nCollecting lightning>=2.0.1 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n  Downloading lightning-2.3.0-py3-none-any.whl.metadata (53 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m930.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting omegaconf<3.0,>=2.1 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\nCollecting pyannote.core>=5.0.0 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\nCollecting pyannote.database>=5.0.1 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n  Downloading pyannote.database-5.1.0-py3-none-any.whl.metadata (1.2 kB)\nCollecting pyannote.metrics>=3.2 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\nCollecting pyannote.pipeline>=3.0.1 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\nCollecting pytorch-metric-learning>=2.1.0 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n  Downloading pytorch_metric_learning-2.5.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: rich>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (13.7.0)\nRequirement already satisfied: semver>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.2)\nRequirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (0.12.1)\nCollecting speechbrain>=0.5.14 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n  Downloading speechbrain-1.0.0-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: tensorboardX>=2.6 in /opt/conda/lib/python3.10/site-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (2.6.2.2)\nCollecting torch-audiomentations>=0.11.0 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n  Downloading torch_audiomentations-0.11.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: torchmetrics>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (1.4.0.post0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2->whisperx==3.1.1) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=2->whisperx==3.1.1) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2->whisperx==3.1.1) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2->whisperx==3.1.1) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2->whisperx==3.1.1) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2->whisperx==3.1.1) (2024.3.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->whisperx==3.1.1) (1.16.0)\nRequirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas->whisperx==3.1.1) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->whisperx==3.1.1) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->whisperx==3.1.1) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->whisperx==3.1.1) (2023.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->whisperx==3.1.1) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->whisperx==3.1.1) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->whisperx==3.1.1) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->whisperx==3.1.1) (2.32.3)\nINFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\nCollecting transformers (from whisperx==3.1.1)\n  Downloading transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.41.0-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Downloading transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->whisperx==3.1.1) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->whisperx==3.1.1) (4.66.4)\nRequirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (0.11.2)\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (2.2.5)\nCollecting antlr4-python3-runtime==4.9.* (from omegaconf<3.0,>=2.1->pyannote.audio==3.1.1->whisperx==3.1.1)\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1) (23.5.26)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1) (3.20.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers->whisperx==3.1.1) (3.1.1)\nRequirement already satisfied: sortedcontainers>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from pyannote.core>=5.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (2.4.0)\nRequirement already satisfied: scipy>=1.1 in /opt/conda/lib/python3.10/site-packages (from pyannote.core>=5.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.11.4)\nCollecting typer>=0.12.1 (from pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx==3.1.1)\n  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: scikit-learn>=0.17.1 in /opt/conda/lib/python3.10/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (1.2.2)\nRequirement already satisfied: docopt>=0.6.2 in /opt/conda/lib/python3.10/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (0.6.2)\nRequirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (0.9.0)\nRequirement already satisfied: matplotlib>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (3.7.5)\nRequirement already satisfied: optuna>=3.1 in /opt/conda/lib/python3.10/site-packages (from pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (3.6.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (2.17.2)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.16.0)\nCollecting hyperpyyaml (from speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1)\n  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (1.4.2)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (0.2.0)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2->whisperx==3.1.1) (1.3.0)\nCollecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1)\n  Downloading julius-0.2.7.tar.gz (59 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: librosa>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.10.2.post1)\nCollecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1)\n  Downloading torch_pitch_shift-1.2.4-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2->whisperx==3.1.1) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->whisperx==3.1.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->whisperx==3.1.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->whisperx==3.1.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->whisperx==3.1.1) (2024.2.2)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio==3.1.1->whisperx==3.1.1) (2.21)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (3.9.1)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.1)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (5.1.1)\nRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.58.1)\nRequirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.8.1)\nRequirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.3.7)\nRequirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.3)\nRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.0.7)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.1.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (9.5.0)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.13.1)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (6.8.2)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (2.0.25)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (3.2.0)\nCollecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1)\n  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.5.4)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: ruamel.yaml>=0.17.28 in /opt/conda/lib/python3.10/site-packages (from hyperpyyaml->speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (0.18.5)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (4.0.3)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.3.5)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.41.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (3.11.0)\nRequirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/lib/python3.10/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (0.2.7)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.3)\nDownloading faster_whisper-1.0.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyannote.audio-3.1.1-py2.py3-none-any.whl (208 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.7/208.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\nDownloading ctranslate2-4.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (192.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.3/192.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lightning-2.3.0-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyannote.database-5.1.0-py3-none-any.whl (48 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\nDownloading pytorch_metric_learning-2.5.0-py3-none-any.whl (119 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.1/119.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading speechbrain-1.0.0-py3-none-any.whl (760 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.1/760.1 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torch_audiomentations-0.11.1-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torch_pitch_shift-1.2.4-py3-none-any.whl (4.9 kB)\nDownloading typer-0.12.3-py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading primePy-1.3-py3-none-any.whl (4.0 kB)\nBuilding wheels for collected packages: whisperx, antlr4-python3-runtime, julius\n  Building wheel for whisperx (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for whisperx: filename=whisperx-3.1.1-py3-none-any.whl size=38605 sha256=789930e4d4e67aa15c900a59839d07193a333a7b27ae84743adbdc98bc18d28f\n  Stored in directory: /tmp/pip-ephem-wheel-cache-s5pjxlp3/wheels/27/fb/53/682b85073a466f1866910d7257233e53b0cc126ab50e7c5373\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=31ae32eaf45910aac82febc7fd6cf66448890338564d2033ee77c46ad552355c\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n  Building wheel for julius (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=faf545dfb90019e7959a651f40b4758914cfc600e2ad6ff63b53245f3364a4e0\n  Stored in directory: /root/.cache/pip/wheels/b9/b2/05/f883527ffcb7f2ead5438a2c23439aa0c881eaa9a4c80256f4\nSuccessfully built whisperx antlr4-python3-runtime julius\nInstalling collected packages: primePy, antlr4-python3-runtime, omegaconf, humanfriendly, einops, ctranslate2, av, pyannote.core, hyperpyyaml, coloredlogs, typer, tokenizers, pytorch-metric-learning, onnxruntime, julius, asteroid-filterbanks, transformers, torch-pitch-shift, speechbrain, pyannote.database, faster-whisper, torch-audiomentations, pyannote.pipeline, pyannote.metrics, lightning, pyannote.audio, whisperx\n  Attempting uninstall: typer\n    Found existing installation: typer 0.9.0\n    Uninstalling typer-0.9.0:\n      Successfully uninstalled typer-0.9.0\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.41.2\n    Uninstalling transformers-4.41.2:\n      Successfully uninstalled transformers-4.41.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nspacy 3.7.3 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\nweasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 asteroid-filterbanks-0.4.0 av-11.0.0 coloredlogs-15.0.1 ctranslate2-4.3.1 einops-0.8.0 faster-whisper-1.0.0 humanfriendly-10.0 hyperpyyaml-1.2.2 julius-0.2.7 lightning-2.3.0 omegaconf-2.3.0 onnxruntime-1.18.0 primePy-1.3 pyannote.audio-3.1.1 pyannote.core-5.0.0 pyannote.database-5.1.0 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pytorch-metric-learning-2.5.0 speechbrain-1.0.0 tokenizers-0.15.2 torch-audiomentations-0.11.1 torch-pitch-shift-1.2.4 transformers-4.39.3 typer-0.12.3 whisperx-3.1.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install dlib","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:28:28.016386Z","iopub.execute_input":"2024-06-26T11:28:28.016883Z","iopub.status.idle":"2024-06-26T11:36:30.642214Z","shell.execute_reply.started":"2024-06-26T11:28:28.016844Z","shell.execute_reply":"2024-06-26T11:36:30.641078Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting dlib\n  Downloading dlib-19.24.4.tar.gz (3.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: dlib\n  Building wheel for dlib (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for dlib: filename=dlib-19.24.4-cp310-cp310-linux_x86_64.whl size=3327190 sha256=51c867480855ddd404b887ee0762183fd1cca189e2b77d616502bb2d26d27f8a\n  Stored in directory: /root/.cache/pip/wheels/08/5e/55/a7db8d57920eb2c2aa41c36dc4c6d3cd12323865de191a7211\nSuccessfully built dlib\nInstalling collected packages: dlib\nSuccessfully installed dlib-19.24.4\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install moviepy","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:36:30.643658Z","iopub.execute_input":"2024-06-26T11:36:30.643991Z","iopub.status.idle":"2024-06-26T11:37:19.331986Z","shell.execute_reply.started":"2024-06-26T11:36:30.643960Z","shell.execute_reply":"2024-06-26T11:37:19.331079Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting moviepy\n  Downloading moviepy-1.0.3.tar.gz (388 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting decorator<5.0,>=4.0.2 (from moviepy)\n  Downloading decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.66.4)\nRequirement already satisfied: requests<3.0,>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.32.3)\nCollecting proglog<=1.0.0 (from moviepy)\n  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.26.4)\nRequirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.33.1)\nCollecting imageio_ffmpeg>=0.2.0 (from moviepy)\n  Downloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (9.5.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (69.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\nDownloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\nDownloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\nBuilding wheels for collected packages: moviepy\n  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110720 sha256=c769b08598da2908c9f233e17ff3793a8c8916688c376b22465a2aebe8e5774f\n  Stored in directory: /root/.cache/pip/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\nSuccessfully built moviepy\nInstalling collected packages: proglog, imageio_ffmpeg, decorator, moviepy\n  Attempting uninstall: decorator\n    Found existing installation: decorator 5.1.1\n    Uninstalling decorator-5.1.1:\n      Successfully uninstalled decorator-5.1.1\nSuccessfully installed decorator-4.4.2 imageio_ffmpeg-0.5.1 moviepy-1.0.3 proglog-0.1.10\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Checking","metadata":{}},{"cell_type":"code","source":"# import cv2\n# import matplotlib.pyplot as plt\n# video_path = \"/kaggle/input/fakeavceleb/FakeAVCeleb_v1.2/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/Caucasian (European)/men/id03205/00150_id00519_wavtolip.mp4\"\n\n# # if not cv2.VideoCapture(video_path).isOpened():\n# #     print(\"Error: Could not open video.\")\n\n# # Open the video file\n# cap = cv2.VideoCapture(video_path)\n# fps = cap.get(cv2.CAP_PROP_FPS)\n# print(\"FPS: \", fps)\n# # Check if the video was opened successfully\n# if not cap.isOpened():\n#     print(\"Error: Could not open video.\")\n#     exit()\n\n\n# # Function to display frame using Matplotlib\n# def display_frame(frame):\n#     # Convert the frame from BGR to RGB\n#     frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n#     plt.imshow(frame_rgb)\n#     plt.axis('off')  # Hide axes\n#     plt.show()\n\n# # Loop to read and display frames\n# while True:\n#     ret, frame = cap.read()\n\n#     # Break the loop if there are no more frames to read\n#     if not ret:\n#         break\n\n#     # Display the frame using Matplotlib\n#     display_frame(frame)\n\n#     # Add a delay to control frame display rate (e.g., 25 milliseconds)\n#     plt.pause(0.025)\n\n# # Release the video capture object\n# cap.release()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:37:19.333512Z","iopub.execute_input":"2024-06-26T11:37:19.334319Z","iopub.status.idle":"2024-06-26T11:37:19.340029Z","shell.execute_reply.started":"2024-06-26T11:37:19.334278Z","shell.execute_reply":"2024-06-26T11:37:19.339143Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing\n","metadata":{"id":"MPLwFoGhyUih"}},{"cell_type":"markdown","source":"## Import Packages","metadata":{}},{"cell_type":"code","source":"import librosa\nimport moviepy.editor as mp\nimport tempfile\nimport numpy as np\n\nimport cv2\nimport dlib\n\nimport whisperx\nimport gc","metadata":{"id":"DKT9iLwhjRLG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"024df252-655d-4f3c-c4c6-a2435d689a49","execution":{"iopub.status.busy":"2024-06-26T11:37:19.342368Z","iopub.execute_input":"2024-06-26T11:37:19.342659Z","iopub.status.idle":"2024-06-26T11:37:56.965597Z","shell.execute_reply.started":"2024-06-26T11:37:19.342632Z","shell.execute_reply":"2024-06-26T11:37:56.964698Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-06-26 11:37:37.864165: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-26 11:37:37.864304: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-26 11:37:38.142476: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Word Alignment Processing\n","metadata":{"id":"isXpqcQakL9y"}},{"cell_type":"code","source":"# CPU\n# device = \"cpu\" # cuda\n# batch_size = 16\n# compute_type = \"float32\" #16\nimport whisperx\n\n# GPU\ndevice = \"cuda\" \nbatch_size = 16\ncompute_type = \"float16\"\n\n# Speech to text transcription model\nmodel = whisperx.load_model(\"large-v2\", device, compute_type=compute_type)\n\ndef getWordAlignment(audio_file):\n    audio = whisperx.load_audio(audio_file)\n    result = model.transcribe(audio, batch_size=batch_size)\n    \n    if (result[\"language\"] != \"en\"):\n        return None\n    \n    # Word alignment model\n    word_model, metadata = whisperx.load_align_model(language_code = result[\"language\"], device = device)\n    \n    result = whisperx.align(result[\"segments\"],\n                        word_model,\n                        metadata,\n                        audio,\n                        device,\n                        return_char_alignments = False)\n\n    print(result[\"segments\"])\n    return result","metadata":{"id":"gw3LuhO6kLKW","colab":{"base_uri":"https://localhost:8080/","height":256,"referenced_widgets":["464a2efc45fb461896d1ef833e96bb0a","1ca2e20d7c194a8f899343a46c6a4280","647220925d1b4fd7baafcca901db82fd","413ed8b4590e410abc7349ae15281692","015c4b25451f4848a821b2784617d9c8","ce6edc35d3dc448a9b3b0211c0ce5c9e","122df8e273d343be99ced55ae44035f5","48f21c837361409c9fff355f0eb83391","49b5f1df784c407bb905bf0bfbfd5a24","676d2cf4f9cf478ea7f873bb8663df75","46494db417db49ddb88b7251bd2b64e3","7b71f3e001464524a1698592dddbc1bd","d7ea5fefa721401a982aab94044ecf2e","64b01f3e6cce4d6ea2d09d4adacee509","a99472e689744d32a515458eb8d4e58e","c21c0030c0034243bcde470dbda95868","764cfaa5a8864d3db69a88a090eb0431","b11e73cb1fe847c9bf005baedb70b07c","5e5fe3566f5844efbd54936aad692c59","4f947b31f89b41d582fd2f19b12fd248","d6bc5c35e11d4bafadc78012c52e94fd","90d3eb4e00f74cadac1e679b5a0a161a","58cd70590ac24792b8d08cc72bf3bafb","efdf5530d0ee432ea9348f4d170b9670","5b729766bee34662920ed4a7734c5133","09d7f61e93d94d7f83b60ba96ac68d7c","d777539d2d1e4423b003a88bf434d6bc","176715771bbb486f95482297e105186e","edc0a80d72894607944e8ae2a3997406","26783545b00d4515aa5919061f63684f","f2fbc2c05cad4bda8afcdd317e8bf92a","a7a39808aaeb4a6c88c782f17b4692fa","383e0e842f6040fa98073c995c5db35d","3ac69ba66b7140a2a549f75b554c51dd","f87557f81f644be18837d5841183a11b","f0eaac040b544ddf893de561a2df10ac","b0528c5b041d41d39b9639a5677b578f","ee8cb3aecce943b889f56bd57e779265","13ad4601cecf4703ab9384033053d1ca","edd404d4a3254e03ba8073533978233b","4f4d3e2f56ed41d8a2780c816ffbd467","26e75d7625034aacae5e8e7343efe8fc","2c5cf27946ca4f81be0f9089a030e4bb","094e347db7064acd972dad45bdac2a4a"]},"outputId":"aed67ec9-0b9f-4da7-df74-121eff12386e","execution":{"iopub.status.busy":"2024-06-26T11:37:56.966746Z","iopub.execute_input":"2024-06-26T11:37:56.967411Z","iopub.status.idle":"2024-06-26T11:38:19.312898Z","shell.execute_reply.started":"2024-06-26T11:37:56.967382Z","shell.execute_reply":"2024-06-26T11:38:19.312055Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocabulary.txt:   0%|          | 0.00/460k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efc107088aee4ec3ac937682b5601902"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.20M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b3d3c0422754f0f822110ace4b115d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.80k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1378b6a3b994edb8a0437165249cb2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f845f10fef394fb9952057598d2f8577"}},"metadata":{}},{"name":"stdout","text":"No language specified, language will be first be detected for each audio file (increases inference time).\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████████████████████████████████| 16.9M/16.9M [00:01<00:00, 15.2MiB/s]\n","output_type":"stream"},{"name":"stdout","text":"Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\nModel was trained with torch 1.10.0+cu102, yours is 2.1.2. Bad things might happen unless you revert torch to 1.x.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get start and end timestamp for each word in a MP4 file\ndef getTimestamp(result):\n    word_timestamp = []\n\n    for item in result[\"segments\"]:\n        for word in item.get(\"words\"):\n            start_end_timestamp = [word.get(\"start\"),word.get(\"end\")]\n            word_timestamp.append(start_end_timestamp)\n\n    return word_timestamp","metadata":{"id":"o0d-998_kUO3","execution":{"iopub.status.busy":"2024-06-26T11:38:19.314278Z","iopub.execute_input":"2024-06-26T11:38:19.314579Z","iopub.status.idle":"2024-06-26T11:38:19.320257Z","shell.execute_reply.started":"2024-06-26T11:38:19.314551Z","shell.execute_reply":"2024-06-26T11:38:19.319440Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Video Processing\n","metadata":{"id":"I7vNwm3EzGDA"}},{"cell_type":"code","source":"face_detector = dlib.get_frontal_face_detector()\n\ndlib_facelandmark = dlib.shape_predictor(\"/kaggle/input/dlib-face-landmarks/shape_predictor_68_face_landmarks.dat\")\n\n# Define fixed size for the mouth ROI\nfixed_width = 100\nfixed_height = 50\n\ndef mouth_extractor(cap, start_timestamp, end_timestamp, fps):\n    # Get frame rate\n    start_frame = int(start_timestamp * fps)\n    end_frame = int(end_timestamp * fps)\n\n    # Set the starting frame\n    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n\n    processed_frame = [] # final processed frame\n\n    missing_frame_thres = (end_frame - start_frame) / 2 # threshold for termination based on missing frame\n\n    missing_frame = 0 # number of missing frame\n\n    first_frame = True\n    num_face_registered = 0 # number of face detected across frame\n\n    all_face = {} # Save all extracted mouth region for each person in the video\n    mouth_open_close_series = {} # Save the difference between mouth top (y) and mouth bottom (y) to determine which person is speaking\n\n    for frame_number in range(start_frame, end_frame+1):\n        ret, frame = cap.read()\n\n        if not ret:\n            print(\"Failed to read frame from video.\")\n            return []\n\n        if (missing_frame >= missing_frame_thres):\n            print(\"Too many missing frame at this section\")\n            return []\n\n        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n        faces = face_detector(gray)\n\n        num_face_detected = len(faces)\n\n        # Check if no faces were detected\n        if num_face_detected == 0:\n            missing_frame = missing_frame + 1\n            continue\n\n        # detected new face in the following frame (after first frame), register new mouth x coordinate\n        if (num_face_detected > num_face_registered) and not first_frame:\n\n            # repeat the process by the number of new face detected\n            for i in range(num_face_detected - num_face_registered):\n                mouth_distance = {}\n                \n                for face in faces:\n                    # get face landmarks\n                    landmarks = dlib_facelandmark(gray, face)\n\n                    # extract mouth landmark at 48 as ID\n                    mouth_x = landmarks.part(48).x - 15\n                    \n                    # Find the nearest mouth in the registered face\n                    nearest_distance = [0,100000]\n                    for registered_mouth in all_face:\n                        # Find the distance between two mouth in x coordinate\n                        difference = abs(registered_mouth - mouth_x)\n                        \n                        # Identify the nearest mouth\n                        if (difference < nearest_distance[1]):\n                            nearest_distance = [mouth_x, difference]\n                    \n                    mouth_distance[nearest_distance[0]] = nearest_distance[1]\n                \n                farthest = [0,0]\n                # Find the mouth with the largest difference in distance\n                for key, distance in mouth_distance.items():\n                    if distance > farthest[1]:\n                        farthest[0] = key\n                        farthest[1] = distance\n                \n                # register new mouth with empty list\n                all_face[farthest[0]] = [] # mouth region\n                mouth_open_close_series[farthest[0]] = 0 # difference between top lip (y) and bottom lip (y)\n\n            # update number of face registered\n            num_face_registered = num_face_detected\n\n\n        for face in faces:\n            # get face landmarks\n            landmarks = dlib_facelandmark(gray, face)\n\n            # extract mouth region\n            mouth_x = landmarks.part(48).x - 15\n            mouth_y = landmarks.part(51).y - 15\n            mouth_w = landmarks.part(54).x - mouth_x + 15\n            mouth_h = landmarks.part(57).y - mouth_y + 15\n\n\n            # When first frame, register the mouth x coordinate to the dictionary\n            if first_frame:\n                num_face_registered = num_face_detected\n                all_face[mouth_x] = [gray[mouth_y:mouth_y + mouth_h, mouth_x:mouth_x + mouth_w]] # mouth region\n                mouth_open_close_series[mouth_x] = abs(landmarks.part(63).y - landmarks.part(67).y) # difference between top lip (y) and bottom lip (y)\n\n\n            else:\n                # Append to the nearest mouth_x list\n                nearest_x = [99999,0]\n\n                for mouth in all_face:\n                    difference = abs(mouth - mouth_x)\n                    if (difference < nearest_x[0]):\n                        nearest_x[0] = difference # difference between two mouth x coordinate\n                        nearest_x[1] = mouth # key\n\n                # Append the frame to the nearest mouth (key)\n                all_face[nearest_x[1]].append(gray[mouth_y:mouth_y + mouth_h, mouth_x:mouth_x + mouth_w]) # mouth region\n                mouth_open_close_series[nearest_x[1]] = mouth_open_close_series[nearest_x[1]] + abs(landmarks.part(63).y - landmarks.part(67).y) # add the difference between top lip (y) and bottom lip (y)\n\n\n                # update the mouth x coordinate (key) with the latest position\n                all_face[mouth_x] = all_face.pop(nearest_x[1])\n                mouth_open_close_series[mouth_x] = mouth_open_close_series.pop(nearest_x[1])\n\n        first_frame = False\n    \n    # Determine the current speaker by the difference between mouth top and bottom position across frame\n    # The speaker will have the largest the difference across frame because they will open and close their mouth\n    speaker_key = max(mouth_open_close_series, key=mouth_open_close_series.get)\n\n    # check number of frame. Return empty list when too many missing frame\n    if len(all_face[speaker_key]) <= missing_frame_thres:\n        return []\n\n    # Resize frame\n    for mouth_roi in all_face[speaker_key]:\n        if mouth_roi.shape[1] < fixed_width or mouth_roi.shape[0] < fixed_height:\n            interpolation_set = cv2.INTER_CUBIC # For upsampling\n        else:\n            interpolation_set = cv2.INTER_AREA # For downsampling\n\n        resized_mouth_roi = cv2.resize(mouth_roi, (fixed_width, fixed_height), interpolation=interpolation_set)\n\n        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n        normalized_frame = resized_mouth_roi / 255\n\n        processed_frame.append(normalized_frame)\n\n    return processed_frame\n\n","metadata":{"id":"XMCqWq8gOrEV","execution":{"iopub.status.busy":"2024-06-26T11:38:19.321889Z","iopub.execute_input":"2024-06-26T11:38:19.322323Z","iopub.status.idle":"2024-06-26T11:38:28.313734Z","shell.execute_reply.started":"2024-06-26T11:38:19.322292Z","shell.execute_reply":"2024-06-26T11:38:28.312636Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Audio Processing\n","metadata":{"id":"33IWfeWz0FFt"}},{"cell_type":"code","source":"def generate_spectrogram(y, sr, start_time, end_time):\n    \n    # Extract the desired clip\n    clip = y[int(start_time*sr):int(end_time*sr)]\n    \n    # Compute the spectrogram\n    Mel_spectrogram = librosa.feature.melspectrogram(y=clip)\n    \n    log_spectrogram = librosa.power_to_db(Mel_spectrogram, ref=np.max)\n\n        \n    return log_spectrogram\n","metadata":{"id":"4AJvDWbY7aBK","execution":{"iopub.status.busy":"2024-06-26T11:38:28.315162Z","iopub.execute_input":"2024-06-26T11:38:28.315566Z","iopub.status.idle":"2024-06-26T11:38:28.334979Z","shell.execute_reply.started":"2024-06-26T11:38:28.315533Z","shell.execute_reply":"2024-06-26T11:38:28.334192Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Start preprocessing","metadata":{}},{"cell_type":"code","source":"# Create folder to output processed data\nimport os\n\nfolder_path = '/kaggle/working/'\n\nfor item in [\"FakeVideo-FakeAudio\",\"FakeVideo-RealAudio\",\"RealVideo-FakeAudio\",\"RealVideo-RealAudio\"]:\n    temp_path = folder_path+item\n    \n    if not os.path.exists(temp_path):\n        os.mkdir(temp_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:38:28.336074Z","iopub.execute_input":"2024-06-26T11:38:28.336348Z","iopub.status.idle":"2024-06-26T11:38:28.351845Z","shell.execute_reply.started":"2024-06-26T11:38:28.336324Z","shell.execute_reply":"2024-06-26T11:38:28.350931Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\npath = \"/kaggle/input/fakeavceleb/FakeAVCeleb_v1.2/FakeAVCeleb_v1.2/\"\ndataset = os.listdir(path)\n\nfinal_dataset = []\n\n# access 4 main folder (FakeVideo-FakeAudio, FakeVideo-RealAudio, RealVideo-RealAudio, RealVideo-FakeAudio)\nfor folder in dataset:\n    if os.path.isdir(path+folder):\n\n        # access 5 main area - African, Asian (East),Asian (South), Caucasian(US),Caucasian (EU) \n        sub_folder = os.listdir(path+folder)\n        for area in sub_folder:\n\n            # access gender folder - male, female\n            area_folder = os.listdir(path+folder+\"/\"+area)\n            for gender in area_folder:\n\n                video_folder = os.listdir(path+folder+\"/\"+area+\"/\"+gender)\n\n                # Randomly sample 5 video folder from the folder                \n                selected_video_folder = random.sample(video_folder, 5)\n\n                # pick one video from each video folder, ignore non-mp4 file\n                for selected_folder in selected_video_folder:\n\n\n                    videos = os.listdir(path+folder+\"/\"+area+\"/\"+gender+\"/\"+selected_folder)\n\n                    for file in videos:\n\n                        video_path = path+folder+\"/\"+area+\"/\"+gender+\"/\"+selected_folder+\"/\"+file\n\n                        #ignore non-mp4 file and video that cannot be opened \n                        if not file.endswith(\".mp4\") or not cv2.VideoCapture(video_path).isOpened():\n                            continue\n\n                        final_dataset.append(video_path)\n\n                        #Only load one video inside the folder\n                        break;\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T12:09:49.421335Z","iopub.execute_input":"2024-06-26T12:09:49.421856Z","iopub.status.idle":"2024-06-26T12:09:54.362543Z","shell.execute_reply.started":"2024-06-26T12:09:49.421825Z","shell.execute_reply":"2024-06-26T12:09:54.361526Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(len(final_dataset))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:38:28.623756Z","iopub.status.idle":"2024-06-26T11:38:28.624099Z","shell.execute_reply.started":"2024-06-26T11:38:28.623935Z","shell.execute_reply":"2024-06-26T11:38:28.623950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_dataset[0].split(\"/\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:38:28.625183Z","iopub.status.idle":"2024-06-26T11:38:28.625530Z","shell.execute_reply.started":"2024-06-26T11:38:28.625343Z","shell.execute_reply":"2024-06-26T11:38:28.625356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Zip folder to download","metadata":{}},{"cell_type":"code","source":"counter = 0\ntotal_video = len(final_dataset)\n\nfor video_path in final_dataset:\n\n    counter = counter +1\n    \n    print(\"Processing File: \", video_path, f\"| Progress---> {counter}/{total_video}\")\n\n    # load the video file\n    video = mp.VideoFileClip(video_path)\n\n    audio = video.audio\n\n    # Save the audio as a temporary WAV file\n    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=True) as tmp_audio_file:\n        audio.write_audiofile(tmp_audio_file.name)\n        tmp_audio = tmp_audio_file.name\n\n        # get word alignment result\n        alignment_result = getWordAlignment(tmp_audio)\n\n        # Load the audio using librosa\n        y, sr = librosa.load(tmp_audio)\n\n    if not alignment_result:\n        counter = counter - 1\n        continue \n\n    # Get start and end timestamp for each word in the audio file\n    word_timestamp = getTimestamp(alignment_result)\n\n\n    for timestamp in word_timestamp:\n        # ensure the timestamp is not empty\n        if (timestamp[0] == None ):\n            continue\n\n        print(f\"Timestamp -> {timestamp[0]} - {timestamp[1]}\")\n        # Read video MP4 File\n        cap = cv2.VideoCapture(video_path)\n        fps = cap.get(cv2.CAP_PROP_FPS)\n        print(\"FPS: \", fps)\n\n        # timestamp[0] -> start time | timestamp[1] -> end time\n        processed_video = mouth_extractor(cap, timestamp[0], timestamp[1], fps)\n\n        # Process and convert audio data to log mel spectrogram\n        processed_audio = generate_spectrogram(y, sr, timestamp[0], timestamp[1])\n        print('Shape: ', processed_audio.shape)\n\n        if processed_audio.shape[1] > 25:\n            print(\"outlier: Audio frame > 25\")\n            continue \n\n        if not processed_video:\n            print(\"empty frame\")\n            continue\n\n        # obtain the filename\n        temp = video_path.split(\"/\")\n        folder = temp[6]\n        filename = os.path.splitext(temp[-1])[0]\n\n        # Create new folder for the data\n        folder_path = f\"/kaggle/working/{folder}/{filename}_{timestamp[0]}_{timestamp[1]}/\"\n        os.mkdir(folder_path)\n\n        np.save(folder_path+\"video\", processed_video)\n        np.save(folder_path+\"audio\", processed_audio)\n\n        print(\"=\"*100)\n        print(f\"Saved Data\")\n        print(\"=\"*100)\n    \n    cap.release()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T12:10:00.755472Z","iopub.execute_input":"2024-06-26T12:10:00.755889Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Processing File:  /kaggle/input/fakeavceleb/FakeAVCeleb_v1.2/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/African/men/id00987/00160_id01207_wavtolip.mp4 | Progress---> 1/200\nMoviePy - Writing audio in /tmp/tmpb3y48mgg.wav\n","output_type":"stream"},{"name":"stderr","text":"                                                       ","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"},{"name":"stdout","text":"Warning: audio is shorter than 30s, language detection may be inaccurate.\nDetected language: en (0.99) in first 30s of audio...\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/torchaudio/models/wav2vec2_fairseq_base_ls960_asr_ls960.pth\" to /root/.cache/torch/hub/checkpoints/wav2vec2_fairseq_base_ls960_asr_ls960.pth\n100%|██████████| 360M/360M [00:01<00:00, 243MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"[{'start': 0.129, 'end': 4.075, 'text': \" Awesome, then there's one in fire all these great records when you start seeing the same name.\", 'words': [{'word': 'Awesome,', 'start': 0.129, 'end': 0.39, 'score': 0.624}, {'word': 'then', 'start': 0.43, 'end': 0.65, 'score': 0.768}, {'word': \"there's\", 'start': 0.69, 'end': 0.91, 'score': 0.853}, {'word': 'one', 'start': 1.01, 'end': 1.111, 'score': 0.836}, {'word': 'in', 'start': 1.151, 'end': 1.231, 'score': 0.362}, {'word': 'fire', 'start': 1.271, 'end': 1.571, 'score': 0.82}, {'word': 'all', 'start': 1.651, 'end': 1.771, 'score': 0.736}, {'word': 'these', 'start': 1.812, 'end': 1.952, 'score': 0.888}, {'word': 'great', 'start': 2.012, 'end': 2.212, 'score': 0.923}, {'word': 'records', 'start': 2.272, 'end': 2.593, 'score': 0.879}, {'word': 'when', 'start': 2.653, 'end': 2.773, 'score': 0.996}, {'word': 'you', 'start': 2.813, 'end': 2.953, 'score': 0.964}, {'word': 'start', 'start': 2.993, 'end': 3.254, 'score': 0.943}, {'word': 'seeing', 'start': 3.294, 'end': 3.574, 'score': 0.654}, {'word': 'the', 'start': 3.614, 'end': 3.674, 'score': 0.987}, {'word': 'same', 'start': 3.714, 'end': 3.894, 'score': 0.801}, {'word': 'name.', 'start': 3.935, 'end': 4.075, 'score': 0.984}]}]\nTimestamp -> 0.129 - 0.39\nFPS:  25.0\nShape:  (128, 12)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.43 - 0.65\nFPS:  25.0\nShape:  (128, 10)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.69 - 0.91\nFPS:  25.0\nShape:  (128, 10)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.01 - 1.111\nFPS:  25.0\nShape:  (128, 5)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.151 - 1.231\nFPS:  25.0\nShape:  (128, 4)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.271 - 1.571\nFPS:  25.0\nShape:  (128, 13)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.651 - 1.771\nFPS:  25.0\nShape:  (128, 6)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.812 - 1.952\nFPS:  25.0\nShape:  (128, 7)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.012 - 2.212\nFPS:  25.0\nShape:  (128, 9)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.272 - 2.593\nFPS:  25.0\nShape:  (128, 14)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.653 - 2.773\nFPS:  25.0\nShape:  (128, 6)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.813 - 2.953\nFPS:  25.0\nShape:  (128, 7)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.993 - 3.254\nFPS:  25.0\nShape:  (128, 12)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.294 - 3.574\nFPS:  25.0\nShape:  (128, 13)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.614 - 3.674\nFPS:  25.0\nShape:  (128, 3)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.714 - 3.894\nFPS:  25.0\nShape:  (128, 8)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.935 - 4.075\nFPS:  25.0\nShape:  (128, 7)\n====================================================================================================\nSaved Data\n====================================================================================================\nProcessing File:  /kaggle/input/fakeavceleb/FakeAVCeleb_v1.2/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/African/men/id01598/00044_id00476_wavtolip.mp4 | Progress---> 2/200\nMoviePy - Writing audio in /tmp/tmp_xhk8wp3.wav\n","output_type":"stream"},{"name":"stderr","text":"                                                        ","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"},{"name":"stdout","text":"Warning: audio is shorter than 30s, language detection may be inaccurate.\nDetected language: en (0.97) in first 30s of audio...\n[{'start': 0.049, 'end': 1.454, 'text': ' Things told his mother like the ends.', 'words': [{'word': 'Things', 'start': 0.049, 'end': 0.35, 'score': 0.99}, {'word': 'told', 'start': 0.43, 'end': 0.611, 'score': 0.823}, {'word': 'his', 'start': 0.651, 'end': 0.731, 'score': 0.845}, {'word': 'mother', 'start': 0.772, 'end': 0.972, 'score': 0.886}, {'word': 'like', 'start': 1.012, 'end': 1.173, 'score': 0.666}, {'word': 'the', 'start': 1.193, 'end': 1.273, 'score': 0.143}, {'word': 'ends.', 'start': 1.293, 'end': 1.454, 'score': 0.59}]}, {'start': 1.574, 'end': 4.805, 'text': \"He said she says, well, they don't win because she's on the back in April too.\", 'words': [{'word': 'He', 'start': 1.574, 'end': 1.655, 'score': 0.894}, {'word': 'said', 'start': 1.675, 'end': 1.835, 'score': 0.739}, {'word': 'she', 'start': 1.855, 'end': 1.976, 'score': 0.705}, {'word': 'says,', 'start': 1.996, 'end': 2.176, 'score': 0.816}, {'word': 'well,', 'start': 2.237, 'end': 2.417, 'score': 0.928}, {'word': 'they', 'start': 2.738, 'end': 2.859, 'score': 0.342}, {'word': \"don't\", 'start': 2.879, 'end': 3.059, 'score': 0.864}, {'word': 'win', 'start': 3.099, 'end': 3.28, 'score': 0.747}, {'word': 'because', 'start': 3.481, 'end': 3.702, 'score': 0.931}, {'word': \"she's\", 'start': 3.722, 'end': 3.882, 'score': 0.67}, {'word': 'on', 'start': 3.902, 'end': 3.982, 'score': 0.848}, {'word': 'the', 'start': 4.003, 'end': 4.083, 'score': 0.281}, {'word': 'back', 'start': 4.123, 'end': 4.263, 'score': 0.874}, {'word': 'in', 'start': 4.304, 'end': 4.364, 'score': 0.462}, {'word': 'April', 'start': 4.404, 'end': 4.645, 'score': 0.836}, {'word': 'too.', 'start': 4.665, 'end': 4.805, 'score': 0.999}]}]\nTimestamp -> 0.049 - 0.35\nFPS:  25.0\nShape:  (128, 13)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.43 - 0.611\nFPS:  25.0\nShape:  (128, 8)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.651 - 0.731\nFPS:  25.0\nShape:  (128, 4)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.772 - 0.972\nFPS:  25.0\nShape:  (128, 9)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.012 - 1.173\nFPS:  25.0\nShape:  (128, 7)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.193 - 1.273\nFPS:  25.0\nShape:  (128, 4)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.293 - 1.454\nFPS:  25.0\nShape:  (128, 7)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.574 - 1.655\nFPS:  25.0\nShape:  (128, 4)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.675 - 1.835\nFPS:  25.0\nShape:  (128, 7)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.855 - 1.976\nFPS:  25.0\nShape:  (128, 6)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.996 - 2.176\nFPS:  25.0\nShape:  (128, 8)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.237 - 2.417\nFPS:  25.0\nShape:  (128, 8)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.738 - 2.859\nFPS:  25.0\nShape:  (128, 6)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.879 - 3.059\nFPS:  25.0\nShape:  (128, 8)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.099 - 3.28\nFPS:  25.0\nShape:  (128, 8)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.481 - 3.702\nFPS:  25.0\nShape:  (128, 10)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.722 - 3.882\nFPS:  25.0\nShape:  (128, 7)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.902 - 3.982\nFPS:  25.0\nShape:  (128, 4)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 4.003 - 4.083\nFPS:  25.0\nShape:  (128, 4)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 4.123 - 4.263\nFPS:  25.0\nShape:  (128, 7)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 4.304 - 4.364\nFPS:  25.0\nShape:  (128, 3)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 4.404 - 4.645\nFPS:  25.0\nShape:  (128, 11)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 4.665 - 4.805\nFPS:  25.0\nShape:  (128, 7)\n====================================================================================================\nSaved Data\n====================================================================================================\nProcessing File:  /kaggle/input/fakeavceleb/FakeAVCeleb_v1.2/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/African/men/id01597/00005_3_id01528_wavtolip.mp4 | Progress---> 3/200\nMoviePy - Writing audio in /tmp/tmpp0t89r5t.wav\n","output_type":"stream"},{"name":"stderr","text":"                                                       ","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"},{"name":"stdout","text":"Warning: audio is shorter than 30s, language detection may be inaccurate.\nDetected language: en (0.99) in first 30s of audio...\n[{'start': 0.049, 'end': 4.377, 'text': \" Got muscles in my sails and you know, I'm a tough guy and I got money and I can buy whatever\", 'words': [{'word': 'Got', 'start': 0.049, 'end': 0.229, 'score': 0.984}, {'word': 'muscles', 'start': 0.269, 'end': 0.55, 'score': 0.869}, {'word': 'in', 'start': 0.61, 'end': 0.69, 'score': 0.787}, {'word': 'my', 'start': 0.71, 'end': 0.831, 'score': 0.866}, {'word': 'sails', 'start': 0.891, 'end': 1.191, 'score': 0.907}, {'word': 'and', 'start': 1.251, 'end': 1.331, 'score': 0.787}, {'word': 'you', 'start': 1.371, 'end': 1.452, 'score': 0.996}, {'word': 'know,', 'start': 1.492, 'end': 1.672, 'score': 0.818}, {'word': \"I'm\", 'start': 1.933, 'end': 2.053, 'score': 0.874}, {'word': 'a', 'start': 2.093, 'end': 2.113, 'score': 0.995}, {'word': 'tough', 'start': 2.153, 'end': 2.373, 'score': 0.971}, {'word': 'guy', 'start': 2.413, 'end': 2.634, 'score': 0.856}, {'word': 'and', 'start': 2.654, 'end': 2.754, 'score': 0.451}, {'word': 'I', 'start': 2.794, 'end': 2.874, 'score': 0.743}, {'word': 'got', 'start': 2.914, 'end': 3.075, 'score': 0.871}, {'word': 'money', 'start': 3.135, 'end': 3.335, 'score': 0.91}, {'word': 'and', 'start': 3.616, 'end': 3.716, 'score': 0.74}, {'word': 'I', 'start': 3.756, 'end': 3.796, 'score': 0.805}, {'word': 'can', 'start': 3.836, 'end': 3.956, 'score': 0.907}, {'word': 'buy', 'start': 3.996, 'end': 4.197, 'score': 0.875}, {'word': 'whatever', 'start': 4.217, 'end': 4.377, 'score': 0.001}]}]\nTimestamp -> 0.049 - 0.229\nFPS:  25.0\nShape:  (128, 8)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.269 - 0.55\nFPS:  25.0\nShape:  (128, 13)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.61 - 0.69\nFPS:  25.0\nShape:  (128, 4)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.71 - 0.831\nFPS:  25.0\nShape:  (128, 6)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.891 - 1.191\nFPS:  25.0\nShape:  (128, 13)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.251 - 1.331\nFPS:  25.0\nShape:  (128, 4)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.371 - 1.452\nFPS:  25.0\nShape:  (128, 4)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.492 - 1.672\nFPS:  25.0\nShape:  (128, 8)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.933 - 2.053\nFPS:  25.0\nShape:  (128, 6)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.093 - 2.113\nFPS:  25.0\nToo many missing frame at this section\nShape:  (128, 1)\nempty frame\nTimestamp -> 2.153 - 2.373\nFPS:  25.0\nShape:  (128, 10)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.413 - 2.634\nFPS:  25.0\nShape:  (128, 10)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.654 - 2.754\nFPS:  25.0\nShape:  (128, 5)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.794 - 2.874\nFPS:  25.0\nShape:  (128, 4)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.914 - 3.075\nFPS:  25.0\nShape:  (128, 7)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.135 - 3.335\nFPS:  25.0\nShape:  (128, 9)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.616 - 3.716\nFPS:  25.0\nShape:  (128, 5)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.756 - 3.796\nFPS:  25.0\nShape:  (128, 2)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.836 - 3.956\nFPS:  25.0\nShape:  (128, 6)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.996 - 4.197\nFPS:  25.0\nShape:  (128, 9)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 4.217 - 4.377\nFPS:  25.0\nFailed to read frame from video.\nShape:  (128, 7)\nempty frame\nProcessing File:  /kaggle/input/fakeavceleb/FakeAVCeleb_v1.2/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/African/men/id04727/00007_id00987_wavtolip.mp4 | Progress---> 4/200\nMoviePy - Writing audio in /tmp/tmp7v2w3684.wav\n","output_type":"stream"},{"name":"stderr","text":"                                                       \r","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\nWarning: audio is shorter than 30s, language detection may be inaccurate.\nDetected language: en (0.98) in first 30s of audio...\n[{'start': 0.029, 'end': 1.372, 'text': ' wars and stuff like that.', 'words': [{'word': 'wars', 'start': 0.029, 'end': 0.43, 'score': 0.89}, {'word': 'and', 'start': 0.49, 'end': 0.59, 'score': 0.764}, {'word': 'stuff', 'start': 0.631, 'end': 0.891, 'score': 0.967}, {'word': 'like', 'start': 0.931, 'end': 1.112, 'score': 0.787}, {'word': 'that.', 'start': 1.152, 'end': 1.372, 'score': 0.788}]}, {'start': 1.653, 'end': 3.999, 'text': 'I mean, the Peabody, this is one of the highest war', 'words': [{'word': 'I', 'start': 1.653, 'end': 1.693, 'score': 0.999}, {'word': 'mean,', 'start': 1.753, 'end': 1.894, 'score': 0.841}, {'word': 'the', 'start': 1.934, 'end': 2.014, 'score': 0.881}, {'word': 'Peabody,', 'start': 2.034, 'end': 2.495, 'score': 0.749}, {'word': 'this', 'start': 2.816, 'end': 2.996, 'score': 0.527}, {'word': 'is', 'start': 3.057, 'end': 3.117, 'score': 0.685}, {'word': 'one', 'start': 3.177, 'end': 3.277, 'score': 0.689}, {'word': 'of', 'start': 3.297, 'end': 3.357, 'score': 0.746}, {'word': 'the', 'start': 3.397, 'end': 3.478, 'score': 0.833}, {'word': 'highest', 'start': 3.518, 'end': 3.798, 'score': 0.836}, {'word': 'war', 'start': 3.839, 'end': 3.999, 'score': 0.978}]}]\nTimestamp -> 0.029 - 0.43\nFPS:  25.0\nShape:  (128, 18)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.49 - 0.59\nFPS:  25.0\nShape:  (128, 5)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.631 - 0.891\nFPS:  25.0\nShape:  (128, 12)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.931 - 1.112\nFPS:  25.0\nShape:  (128, 8)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.152 - 1.372\nFPS:  25.0\nShape:  (128, 10)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.653 - 1.693\nFPS:  25.0\nShape:  (128, 2)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.753 - 1.894\nFPS:  25.0\nShape:  (128, 7)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.934 - 2.014\nFPS:  25.0\nShape:  (128, 4)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.034 - 2.495\nFPS:  25.0\nShape:  (128, 20)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.816 - 2.996\nFPS:  25.0\nShape:  (128, 8)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.057 - 3.117\nFPS:  25.0\nShape:  (128, 3)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.177 - 3.277\nFPS:  25.0\nShape:  (128, 5)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.297 - 3.357\nFPS:  25.0\nShape:  (128, 3)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.397 - 3.478\nFPS:  25.0\nShape:  (128, 4)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.518 - 3.798\nFPS:  25.0\nShape:  (128, 13)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.839 - 3.999\nFPS:  25.0\nFailed to read frame from video.\nShape:  (128, 7)\nempty frame\nProcessing File:  /kaggle/input/fakeavceleb/FakeAVCeleb_v1.2/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/African/men/id00781/00092_id00476_UgdYVJ6xPYg_faceswap_id02494_wavtolip.mp4 | Progress---> 5/200\nMoviePy - Writing audio in /tmp/tmpi50su8lk.wav\n","output_type":"stream"},{"name":"stderr","text":"                                                       ","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"},{"name":"stdout","text":"Warning: audio is shorter than 30s, language detection may be inaccurate.\nDetected language: en (0.99) in first 30s of audio...\n[{'start': 0.07, 'end': 1.59, 'text': ' Thank you Double Down on iTop.', 'words': [{'word': 'Thank', 'start': 0.07, 'end': 0.313, 'score': 0.952}, {'word': 'you', 'start': 0.333, 'end': 0.455, 'score': 0.897}, {'word': 'Double', 'start': 0.475, 'end': 0.759, 'score': 0.708}, {'word': 'Down', 'start': 0.779, 'end': 1.002, 'score': 0.924}, {'word': 'on', 'start': 1.063, 'end': 1.144, 'score': 0.677}, {'word': 'iTop.', 'start': 1.225, 'end': 1.59, 'score': 0.743}]}]\nTimestamp -> 0.07 - 0.313\nFPS:  25.0\nShape:  (128, 11)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.333 - 0.455\nFPS:  25.0\nShape:  (128, 6)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.475 - 0.759\nFPS:  25.0\nShape:  (128, 13)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.779 - 1.002\nFPS:  25.0\nShape:  (128, 10)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.063 - 1.144\nFPS:  25.0\nShape:  (128, 4)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.225 - 1.59\nFPS:  25.0\nShape:  (128, 16)\n====================================================================================================\nSaved Data\n====================================================================================================\nProcessing File:  /kaggle/input/fakeavceleb/FakeAVCeleb_v1.2/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/African/women/id00577/00010_id04820_64ybrA1atlM_id04437_wavtolip.mp4 | Progress---> 6/200\nMoviePy - Writing audio in /tmp/tmprkt1jkhh.wav\n","output_type":"stream"},{"name":"stderr","text":"                                                       ","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"},{"name":"stdout","text":"Warning: audio is shorter than 30s, language detection may be inaccurate.\nDetected language: en (0.98) in first 30s of audio...\n[{'start': 0.069, 'end': 3.816, 'text': \" Comment and let me see how easy it is to get something that's going to Cold Stone.\", 'words': [{'word': 'Comment', 'start': 0.069, 'end': 0.47, 'score': 0.626}, {'word': 'and', 'start': 0.51, 'end': 0.61, 'score': 0.325}, {'word': 'let', 'start': 0.65, 'end': 0.81, 'score': 0.92}, {'word': 'me', 'start': 0.851, 'end': 0.951, 'score': 0.831}, {'word': 'see', 'start': 0.991, 'end': 1.171, 'score': 0.806}, {'word': 'how', 'start': 1.211, 'end': 1.391, 'score': 0.964}, {'word': 'easy', 'start': 1.452, 'end': 1.652, 'score': 0.276}, {'word': 'it', 'start': 1.672, 'end': 1.712, 'score': 0.169}, {'word': 'is', 'start': 1.772, 'end': 1.872, 'score': 0.661}, {'word': 'to', 'start': 1.892, 'end': 2.013, 'score': 0.514}, {'word': 'get', 'start': 2.033, 'end': 2.193, 'score': 0.81}, {'word': 'something', 'start': 2.233, 'end': 2.574, 'score': 0.916}, {'word': \"that's\", 'start': 2.614, 'end': 2.854, 'score': 0.899}, {'word': 'going', 'start': 2.894, 'end': 3.115, 'score': 0.897}, {'word': 'to', 'start': 3.155, 'end': 3.255, 'score': 0.767}, {'word': 'Cold', 'start': 3.295, 'end': 3.555, 'score': 0.737}, {'word': 'Stone.', 'start': 3.575, 'end': 3.816, 'score': 0.594}]}]\nTimestamp -> 0.069 - 0.47\nFPS:  25.0\nShape:  (128, 18)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.51 - 0.61\nFPS:  25.0\nShape:  (128, 5)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.65 - 0.81\nFPS:  25.0\nShape:  (128, 7)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.851 - 0.951\nFPS:  25.0\nToo many missing frame at this section\nShape:  (128, 5)\nempty frame\nTimestamp -> 0.991 - 1.171\nFPS:  25.0\nToo many missing frame at this section\nShape:  (128, 8)\nempty frame\nTimestamp -> 1.211 - 1.391\nFPS:  25.0\nShape:  (128, 8)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.452 - 1.652\nFPS:  25.0\nShape:  (128, 9)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.672 - 1.712\nFPS:  25.0\nShape:  (128, 2)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.772 - 1.872\nFPS:  25.0\nShape:  (128, 5)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.892 - 2.013\nFPS:  25.0\nShape:  (128, 6)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.033 - 2.193\nFPS:  25.0\nShape:  (128, 7)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.233 - 2.574\nFPS:  25.0\nShape:  (128, 15)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.614 - 2.854\nFPS:  25.0\nShape:  (128, 11)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.894 - 3.115\nFPS:  25.0\nShape:  (128, 10)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.155 - 3.255\nFPS:  25.0\nShape:  (128, 5)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.295 - 3.555\nFPS:  25.0\nShape:  (128, 12)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.575 - 3.816\nFPS:  25.0\nShape:  (128, 11)\n====================================================================================================\nSaved Data\n====================================================================================================\nProcessing File:  /kaggle/input/fakeavceleb/FakeAVCeleb_v1.2/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/African/women/id04705/00408_id02808_wavtolip.mp4 | Progress---> 7/200\nMoviePy - Writing audio in /tmp/tmp3zj1muj_.wav\n","output_type":"stream"},{"name":"stderr","text":"                                                        ","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"},{"name":"stdout","text":"Warning: audio is shorter than 30s, language detection may be inaccurate.\nDetected language: en (0.99) in first 30s of audio...\n[{'start': 0.049, 'end': 1.03, 'text': ' Yeah, I do.', 'words': [{'word': 'Yeah,', 'start': 0.049, 'end': 0.51, 'score': 0.698}, {'word': 'I', 'start': 0.77, 'end': 0.85, 'score': 0.865}, {'word': 'do.', 'start': 0.87, 'end': 1.03, 'score': 0.826}]}, {'start': 1.071, 'end': 7.139, 'text': 'I mean, people sort of industry, the Clinton, you know, they just when we pray out with time, they just get, you know, sometimes I just talk to me like.', 'words': [{'word': 'I', 'start': 1.071, 'end': 1.131, 'score': 0.94}, {'word': 'mean,', 'start': 1.171, 'end': 1.331, 'score': 0.925}, {'word': 'people', 'start': 1.371, 'end': 1.631, 'score': 0.889}, {'word': 'sort', 'start': 1.651, 'end': 1.852, 'score': 0.847}, {'word': 'of', 'start': 1.872, 'end': 1.932, 'score': 0.727}, {'word': 'industry,', 'start': 1.992, 'end': 2.393, 'score': 0.837}, {'word': 'the', 'start': 2.473, 'end': 2.573, 'score': 0.35}, {'word': 'Clinton,', 'start': 2.593, 'end': 2.993, 'score': 0.829}, {'word': 'you', 'start': 3.194, 'end': 3.294, 'score': 0.764}, {'word': 'know,', 'start': 3.314, 'end': 3.434, 'score': 0.787}, {'word': 'they', 'start': 3.454, 'end': 3.594, 'score': 0.9}, {'word': 'just', 'start': 3.614, 'end': 3.734, 'score': 0.945}, {'word': 'when', 'start': 3.775, 'end': 3.915, 'score': 0.873}, {'word': 'we', 'start': 3.935, 'end': 4.035, 'score': 0.994}, {'word': 'pray', 'start': 4.055, 'end': 4.215, 'score': 0.709}, {'word': 'out', 'start': 4.275, 'end': 4.355, 'score': 0.904}, {'word': 'with', 'start': 4.395, 'end': 4.576, 'score': 0.462}, {'word': 'time,', 'start': 4.616, 'end': 4.856, 'score': 0.839}, {'word': 'they', 'start': 5.117, 'end': 5.257, 'score': 0.954}, {'word': 'just', 'start': 5.277, 'end': 5.397, 'score': 0.953}, {'word': 'get,', 'start': 5.437, 'end': 5.557, 'score': 0.915}, {'word': 'you', 'start': 5.597, 'end': 5.677, 'score': 0.857}, {'word': 'know,', 'start': 5.717, 'end': 5.858, 'score': 0.866}, {'word': 'sometimes', 'start': 5.878, 'end': 6.198, 'score': 0.905}, {'word': 'I', 'start': 6.258, 'end': 6.338, 'score': 0.753}, {'word': 'just', 'start': 6.358, 'end': 6.499, 'score': 0.745}, {'word': 'talk', 'start': 6.539, 'end': 6.759, 'score': 0.926}, {'word': 'to', 'start': 6.779, 'end': 6.819, 'score': 0.96}, {'word': 'me', 'start': 6.859, 'end': 6.979, 'score': 0.958}, {'word': 'like.', 'start': 7.019, 'end': 7.139, 'score': 0.92}]}]\nTimestamp -> 0.049 - 0.51\nFPS:  25.0\nShape:  (128, 20)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.77 - 0.85\nFPS:  25.0\nShape:  (128, 4)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 0.87 - 1.03\nFPS:  25.0\nToo many missing frame at this section\nShape:  (128, 7)\nempty frame\nTimestamp -> 1.071 - 1.131\nFPS:  25.0\nToo many missing frame at this section\nShape:  (128, 3)\nempty frame\nTimestamp -> 1.171 - 1.331\nFPS:  25.0\nToo many missing frame at this section\nShape:  (128, 7)\nempty frame\nTimestamp -> 1.371 - 1.631\nFPS:  25.0\nShape:  (128, 12)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.651 - 1.852\nFPS:  25.0\nShape:  (128, 9)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.872 - 1.932\nFPS:  25.0\nShape:  (128, 3)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 1.992 - 2.393\nFPS:  25.0\nShape:  (128, 18)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.473 - 2.573\nFPS:  25.0\nShape:  (128, 5)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 2.593 - 2.993\nFPS:  25.0\nShape:  (128, 18)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.194 - 3.294\nFPS:  25.0\nShape:  (128, 5)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.314 - 3.434\nFPS:  25.0\nShape:  (128, 6)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.454 - 3.594\nFPS:  25.0\nShape:  (128, 7)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 3.614 - 3.734\nFPS:  25.0\nToo many missing frame at this section\nShape:  (128, 6)\nempty frame\nTimestamp -> 3.775 - 3.915\nFPS:  25.0\nToo many missing frame at this section\nShape:  (128, 7)\nempty frame\nTimestamp -> 3.935 - 4.035\nFPS:  25.0\nToo many missing frame at this section\nShape:  (128, 5)\nempty frame\nTimestamp -> 4.055 - 4.215\nFPS:  25.0\nToo many missing frame at this section\nShape:  (128, 7)\nempty frame\nTimestamp -> 4.275 - 4.355\nFPS:  25.0\nShape:  (128, 4)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 4.395 - 4.576\nFPS:  25.0\nShape:  (128, 8)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 4.616 - 4.856\nFPS:  25.0\nShape:  (128, 11)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 5.117 - 5.257\nFPS:  25.0\nShape:  (128, 7)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 5.277 - 5.397\nFPS:  25.0\nShape:  (128, 6)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 5.437 - 5.557\nFPS:  25.0\nShape:  (128, 6)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 5.597 - 5.677\nFPS:  25.0\nShape:  (128, 4)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 5.717 - 5.858\nFPS:  25.0\nShape:  (128, 7)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 5.878 - 6.198\nFPS:  25.0\nShape:  (128, 14)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 6.258 - 6.338\nFPS:  25.0\nShape:  (128, 4)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 6.358 - 6.499\nFPS:  25.0\nShape:  (128, 7)\n====================================================================================================\nSaved Data\n====================================================================================================\nTimestamp -> 6.539 - 6.759\nFPS:  25.0\nToo many missing frame at this section\nShape:  (128, 10)\nempty frame\nTimestamp -> 6.779 - 6.819\nFPS:  25.0\nToo many missing frame at this section\nShape:  (128, 2)\nempty frame\nTimestamp -> 6.859 - 6.979\nFPS:  25.0\nToo many missing frame at this section\nShape:  (128, 6)\nempty frame\nTimestamp -> 7.019 - 7.139\nFPS:  25.0\nShape:  (128, 6)\n====================================================================================================\nSaved Data\n====================================================================================================\nProcessing File:  /kaggle/input/fakeavceleb/FakeAVCeleb_v1.2/FakeAVCeleb_v1.2/FakeVideo-FakeAudio/African/women/id04245/00072_id04736_wavtolip.mp4 | Progress---> 8/200\nMoviePy - Writing audio in /tmp/tmp8_av8f_l.wav\n","output_type":"stream"},{"name":"stderr","text":"                                                        ","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"},{"name":"stdout","text":"Warning: audio is shorter than 30s, language detection may be inaccurate.\nDetected language: en (1.00) in first 30s of audio...\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r FakeAVCeleb_GS_Validation.zip /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:38:28.628814Z","iopub.status.idle":"2024-06-26T11:38:28.629239Z","shell.execute_reply.started":"2024-06-26T11:38:28.629007Z","shell.execute_reply":"2024-06-26T11:38:28.629024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n\n# def remove_directory_and_contents(directory_path):\n#     try:\n#         shutil.rmtree(directory_path)\n#         print(f\"Successfully removed the directory and all its contents: {directory_path}\")\n#     except Exception as e:\n#         print(f\"Failed to remove the directory {directory_path}. Reason: {e}\")\n\n# # Example usage\n# directory_path = \"/kaggle/working/\"\n# remove_directory_and_contents(directory_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:38:28.630995Z","iopub.status.idle":"2024-06-26T11:38:28.631320Z","shell.execute_reply.started":"2024-06-26T11:38:28.631156Z","shell.execute_reply":"2024-06-26T11:38:28.631169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read processed FakeAVCeleb","metadata":{}},{"cell_type":"code","source":"# Read Dataset\nbase_path = '/kaggle/input/fakeavceleb-validation'\n\nvideo_data = []\naudio_data = []\nlabels = []\n\nfor main_folder in os.listdir(base_path):\n    \n    temp_path = os.path.join(base_path, main_folder,'content')\n    \n    for sub_folder in os.listdir(temp_path):\n        \n        temp_path_2 = os.path.join(temp_path, sub_folder)\n        print(sub_folder)\n        for video_audio_folder in os.listdir(temp_path_2):\n            video_data.append(np.load(os.path.join(temp_path_2, video_audio_folder, \"video.npy\")))\n            audio_data.append(np.load(os.path.join(temp_path_2, video_audio_folder, \"audio.npy\")))\n            \n            if 'Fake' in sub_folder:\n                labels.append('Fake')\n            else:\n                labels.append('Real')\n\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize padded video data\nvideo_data = pad_sequences(video_data, maxlen = 19,dtype='float32', padding='post', truncating='post', value=0.0 )\n\n# Add a channel dimension\nvideo_data = np.expand_dims(video_data, axis=-1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find global min and max of log mel spectrogram for normalziation purpose\nglobal_min = min(np.min(spectrogram) for spectrogram in audio_data)\nglobal_max = max(np.max(spectrogram) for spectrogram in audio_data)\n\nfor i, audio in enumerate(audio_data):\n    # transpose audio data\n    transpose_audio = audio.transpose()\n    \n    # Normalize the log-mel spectrogram\n    normalized_audio = (transpose_audio - global_min) / (global_max - global_min)\n    \n    audio_data[i] = normalized_audio\n    \n\n# add paddding to audio data\naudio_data = pad_sequences(audio_data, maxlen = 25, dtype='float32', padding='post', truncating='post', value=0.0 )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"video_data = np.array(video_data)\naudio_data = np.array(audio_data)\nencoded_labels = LabelEncoder().fit_transform(labels)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save unsplited data for cross_validation\nnp.savez_compressed('Processed_FakeAVCeleb.npz', \n                   video_data=video_data, \n                   audio_data=audio_data, \n                   encoded_labels=encoded_labels)","metadata":{},"execution_count":null,"outputs":[]}]}